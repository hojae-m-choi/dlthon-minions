{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b19dd60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in /opt/conda/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: lightning_utilities in /opt/conda/lib/python3.9/site-packages (0.11.3.post0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.9/site-packages (4.12.2)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.9/site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: fsspec[http] in /opt/conda/lib/python3.9/site-packages (2024.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U lightning lightning_utilities typing_extensions pytorch-lightning torchmetrics fsspec[http] --no-deps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9866da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch>2 in /opt/conda/lib/python3.9/site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (0.18.1+cu118)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.9/site-packages (2.3.1+cu118)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from torch>2) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.9/site-packages (from torch>2) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.9/site-packages (from torch>2) (11.8.86)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.9/site-packages (from torch>2) (11.8.89)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>2) (2.6.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.9/site-packages (from torch>2) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /opt/conda/lib/python3.9/site-packages (from torch>2) (8.7.0.84)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch>2) (3.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.9/site-packages (from torch>2) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.9/site-packages (from torch>2) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.9/site-packages (from torch>2) (10.9.0.58)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>2) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.9/site-packages (from torch>2) (11.7.5.86)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.9/site-packages (from torch>2) (2.3.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch>2) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.9/site-packages (from torch>2) (10.3.0.86)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch>2) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /opt/conda/lib/python3.9/site-packages (from torch>2) (2.20.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision) (1.21.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>2) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.9/site-packages (from sympy->torch>2) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=true\n",
    "!pip install \"torch>2\" torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "311fcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 설치한 폰트를 matplotlib에서 사용할 수 있도록 설정\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 나눔 폰트 경로 설정\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "\n",
    "# 폰트 매니저에 폰트 추가\n",
    "fm.fontManager.addfont(font_path)\n",
    "plt.rc('font', family='NanumGothic')  # 폰트 설정\n",
    "\n",
    "\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9780552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache() \n",
    "\n",
    "import gc\n",
    "gc.collect()  # Additional step to ensure garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe36cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path =\"/aiffel/aiffel/dlthon-minions/share/data/conversations.csv\"\n",
    "origin_data = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd44c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class'를 'type'으로 매핑하는 딕셔너리 생성하기\n",
    "class_to_type = {\n",
    "    '협박 대화': 0,\n",
    "    '갈취 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '기타 괴롭힘 대화': 3,\n",
    "    '일반 대화': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6769387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class' 열을 기반으로 새로운 'type' 열 추가하기\n",
    "origin_data['label'] = origin_data['class'].map(class_to_type)\n",
    "origin_data.drop(['idx', 'class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88d1f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 정의하기\n",
    "def preprocess_sentence(sentence): \n",
    "    # \\n을 공백으로 바꾸기\n",
    "    sentence = re.sub(\"\\n\", \" \", sentence)\n",
    "    \n",
    "    # (ㄱ-ㅎ, ㅏ-ㅣ, \".\", \"?\", \"!\", \",\", ' ')를 제외한 모든 문자를 없애기\n",
    "    sentence = re.sub(\"[^ㄱ-ㅣ가-힣.?!, ]\", \"\", sentence)\n",
    "    \n",
    "    # 단어와 구두점(punctuation) 사이에 공백 추가하기\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a452dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 데이터 새로운 column에 저장하기\n",
    "preprocessed = origin_data['conversation'].apply(preprocess_sentence).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de3027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 최대 길이 128으로 설정\n",
    "MAX_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676a3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = \"gogamza/kobart-base-v2\"\n",
    "\n",
    "from transformers import BartTokenizerFast, PreTrainedTokenizerFast\n",
    "# 각 conversation을 토큰화하여 새로운 열 'tokenized'에 저장\n",
    "tokenizer=PreTrainedTokenizerFast.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff377bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어사전 크기 20000으로 제한\n",
    "VOCAB_SIZE=len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9147006",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer(\n",
    "    preprocessed, \n",
    "    max_length=MAX_LENGTH,\n",
    "    padding='max_length',  # Pad to the max_length\n",
    "    truncation=True,       # Truncate sequences to the max_length\n",
    "    return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d72aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a75797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, StackDataset\n",
    "\n",
    "dataset = StackDataset(**dict(tokenized), \n",
    "                       labels=origin_data['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dac280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split, default_collate\n",
    "generator2 = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset  = random_split(dataset, [0.8, 0.1, 0.1], generator=generator2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6266976c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 3960\n",
      "Number of validation data: 495\n",
      "Number of test data: 495\n"
     ]
    }
   ],
   "source": [
    "print('Number of training data:', len(train_dataset))\n",
    "print('Number of validation data:', len(val_dataset))\n",
    "print('Number of test data:', len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01287276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 준비 함수 정의하기\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def prepare_dataloaders(train_dataset, val_dataset, test_dataset, batch_size, **kwargs):\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed55365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, StackDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from transformers import BartModel, BartConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae24a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb==0.16.0 -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b097dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /aiffel/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key='746fb761ab2f1b53db2dafef7340caad69224513')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f43686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_table(cm, epoch=''):\n",
    "    title = \"Overall Prediction Result\"\n",
    "    # 실제 클래스명으로 변환\n",
    "    classes = [\n",
    "        '협박 대화 (0)',\n",
    "        '갈취 대화 (1)',\n",
    "        '직장 내 괴롭힘 대화 (2)',\n",
    "        '기타 괴롭힘 대화 (3)',\n",
    "        '일반 대화 (4)'\n",
    "    ]\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes, annot_kws={'size': 30})\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(title)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21aebf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class CompareResultsCallback:\n",
    "    def __init__(self, class_num):\n",
    "        self.class_num = class_num\n",
    "\n",
    "    def plot_confusion_matrix(self, model, test_loader, device):\n",
    "        model.eval()\n",
    "        pred_ = []\n",
    "        y_ = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = {key: d.to(device) for key, d in batch.items()}\n",
    "                y_test_batch = batch['labels']\n",
    "                loss, logits = model(**batch)\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                pred_.extend(pred.cpu().numpy())\n",
    "                y_.extend(y_test_batch.cpu().numpy())\n",
    "        \n",
    "        cm = confusion_matrix(y_, pred_)\n",
    "        \n",
    "        # 표 그리기\n",
    "        cm_plot = plot_table(cm)\n",
    "\n",
    "        # wandb에 로그로 저장\n",
    "        cm_image = wandb.Image(cm_plot)\n",
    "        wandb.log({\"Overall Prediction Result\": cm_image})\n",
    "\n",
    "    def __call__(self, model, test_loader, device):\n",
    "        self.plot_confusion_matrix(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06752c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BART 분류기 클래스 정의하기\n",
    "class BartForSequenceClassification(nn.Module):\n",
    "    def __init__(self, num_labels, wandb_config):\n",
    "        super(BartForSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.config = BartConfig.from_pretrained(PRETRAINED_MODEL, num_labels=num_labels)\n",
    "        self.bart = BartModel.from_pretrained(PRETRAINED_MODEL, config=self.config)\n",
    "        \n",
    "        self.classifier = nn.Sequential()\n",
    "        for _ in range(wandb_config.classifier_num_layer-1):\n",
    "            self.classifier.append(nn.Dropout(0.1))\n",
    "            self.classifier.append(nn.Linear(self.config.hidden_size, self.config.hidden_size))\n",
    "            self.classifier.append( nn.GELU() )\n",
    "        self.classifier.append(nn.Dropout(0.1))\n",
    "        self.classifier.append(nn.Linear(self.config.hidden_size, num_labels))\n",
    "        \n",
    "    def forward(self, *args, token_type_ids=None, labels=None, **kwargs, ): #input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.bart(*args, **kwargs,)\n",
    "        pooled_output = outputs[0][:, -1, :]  # 마지막 토큰의 출력 사용\n",
    "#         pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        return loss, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375de296",
   "metadata": {},
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=\"all\")\n",
    "trainer = Trainer(logger=wandb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06c0c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정 함수 정의하기\n",
    "def get_optimizer(optimizer_name, parameters, learning_rate):\n",
    "    if optimizer_name == \"adam\":\n",
    "        return torch.optim.Adam(parameters, lr=learning_rate)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        return torch.optim.SGD(parameters, lr=learning_rate)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        return torch.optim.RMSprop(parameters, lr=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fd34375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def save_model(log_dir, model_state_dict, epoch, val_metrics_dict):\n",
    "    model_path = os.path.join(log_dir, f'model_epoch{epoch}.pth')\n",
    "    torch.save(model_state_dict, model_path)\n",
    "        \n",
    "    # Create an artifact\n",
    "    meta_data = {\n",
    "        'epoch': epoch, \n",
    "        'pre_trained_model': PRETRAINED_MODEL\n",
    "    }\n",
    "    meta_data.update(val_metrics_dict)\n",
    "    \n",
    "    artifact = wandb.Artifact(\n",
    "        name=f'model-epoch-{epoch}',\n",
    "        type='model',\n",
    "        metadata=meta_data,\n",
    "#         description='A model trained on the XYZ dataset for 10 epochs',\n",
    "    )\n",
    "\n",
    "    # Add a file to the artifact\n",
    "    artifact.add_file(model_path)\n",
    "\n",
    "    # Log the artifact\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "def eval_model(model, val_loader, device, prefix='', verbose=False):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pred_val = []\n",
    "    y_val = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader) if verbose else val_loader:\n",
    "            batch = {key: d.to(device) for key, d in batch.items()}\n",
    "            y_val_batch = batch['labels']\n",
    "            loss, logits = model(**batch)\n",
    "            val_loss += loss.item()\n",
    "            pred = logits.argmax(dim=-1)\n",
    "            correct += (pred == y_val_batch).sum().item()\n",
    "            total += y_val_batch.size(0)\n",
    "            y_val.extend(y_val_batch.cpu().numpy())\n",
    "            pred_val.extend(pred.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = correct / total\n",
    "    f1_score_mic = f1_score(y_val, pred_val, average='micro')\n",
    "    f1_score_mac = f1_score(y_val, pred_val, average='macro')\n",
    "    metrics_dict = {\n",
    "        f\"{prefix}loss\": val_loss, \n",
    "        f\"{prefix}accuracy\": accuracy,\n",
    "        f\"{prefix}f1_micro\": f1_score_mic,\n",
    "        f\"{prefix}f1_macro\": f1_score_mac,\n",
    "    }\n",
    "    wandb.log(metrics_dict)\n",
    "    model.train()\n",
    "    return metrics_dict\n",
    "\n",
    "\n",
    "# 훈련 함수 정의하기\n",
    "def train(train_dataset, val_dataset, test_dataset, default_config, log_dir='logs'):\n",
    "    wandb.init(config=default_config)\n",
    "    config = wandb.config\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    log_dir = os.path.join(log_dir, f'{wandb.run.id}') # current_run_id\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    train_loader, val_loader, test_loader = prepare_dataloaders(\n",
    "        train_dataset, val_dataset, test_dataset, \n",
    "        config.batch_size,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=\"cuda\"\n",
    "    )\n",
    "    \n",
    "    model = BartForSequenceClassification(config.class_num, config).to(device)\n",
    "    \n",
    "    if config.freeze_backbone:\n",
    "        for w in model.bart.parameters():\n",
    "            w._trainable = False\n",
    "        training_params = model.classifier.parameters()\n",
    "    else:\n",
    "        training_params = model.parameters()\n",
    "\n",
    "    optimizer = get_optimizer(config.optimizer, training_params, config.learning_rate)\n",
    "    \n",
    "    cm_callback = CompareResultsCallback(config.class_num)\n",
    "    \n",
    "    step = 0\n",
    "    best_val_loss = 1e9\n",
    "    for epoch in range(config.epoch):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            step += 1\n",
    "            batch = {key: d.to(device) for key, d in batch.items()}\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss, logits = model(**batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step // 100 == 0:\n",
    "                wandb.log({'trn_batch_loss': loss})\n",
    "                val_metrics_dict = eval_model(model, val_loader, device, prefix='val_')\n",
    "                if val_metrics_dict['val_loss'] < best_val_loss:\n",
    "                    best_val_loss = val_metrics_dict['val_loss']\n",
    "                    best_model_state_dict = model.state_dict()\n",
    "                    \n",
    "        # end of epoch\n",
    "        save_model(log_dir, model.state_dict(), epoch, val_metrics_dict)\n",
    "        cm_callback(model, val_loader, device)\n",
    "\n",
    "    # end of training\n",
    "    save_model(log_dir, best_model_state_dict, 'best', val_metrics_dict)\n",
    "    val_metrics_dict = eval_model(model, val_loader, device, prefix='val_')\n",
    "    best_val_loss = min(best_val_loss, val_metrics_dict['val_loss'])\n",
    "\n",
    "    # 테스트 단계\n",
    "    cm_callback(model, test_loader, device)\n",
    "    metrics_dict = eval_model(model, test_loader, device, prefix='test_')\n",
    "    save_model(log_dir, model.state_dict(), 'latest', metrics_dict)  \n",
    "    wandb.log({\n",
    "        \"Test Accuracy Rate\": metrics_dict['test_accuracy'],\n",
    "        \"Test F1 Score (macro)\": metrics_dict['test_f1_macro'],\n",
    "        \"Test Error Rate\": 1 - metrics_dict['test_accuracy'],\n",
    "    })\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "478c660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split, default_collate\n",
    "\n",
    "# 스윕 훈련 함수 정의하기\n",
    "def sweep_train():\n",
    "    # 데이터 분할하기\n",
    "    generator2 = torch.Generator().manual_seed(42)\n",
    "    train_dataset, val_dataset, test_dataset  = random_split(dataset, [0.8, 0.1, 0.1], generator=generator2)\n",
    "    # y 데이터의 최대값 + 1 을 class_num으로 설정하기\n",
    "    default_config[\"class_num\"] = max(origin_data['label']) + 1\n",
    "    \n",
    "    train(\n",
    "        train_dataset, val_dataset, test_dataset, \n",
    "        default_config=default_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f381d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 설정\n",
    "default_config = {\n",
    "    \"batch_size\": 24,\n",
    "    \"epoch\": 5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer\": \"adam\",\n",
    "    'freeze_backbone': True,\n",
    "    \"class_num\": 5,  # 클래스 수 (필요에 따라 수정)\n",
    "    \"classifier_num_layer\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d85e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스윕 구성하기\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'parameters': {\n",
    "        'batch_size': {\n",
    "            'values': [8, 16, 24, 32]\n",
    "        },\n",
    "        'epoch': {\n",
    "            'values': [5, 10]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'max': 0.1,\n",
    "            'min': 0.001\n",
    "        },\n",
    "        \"classifier_num_layer\": {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        \"freeze_backbone\": {\n",
    "            'values': [True, False]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'sgd', 'rmsprop']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a75253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: n6a4o84l\n",
      "Sweep URL: https://wandb.ai/aiffel_minions/DLthon_finetune_koBart/sweeps/n6a4o84l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9x0ocr7n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclassifier_num_layer: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfreeze_backbone: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07274125430796448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhojae-choi\u001b[0m (\u001b[33maiffel_minions\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/dlthon-minions/dlthon-stuart/wandb/run-20240627_012057-9x0ocr7n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aiffel_minions/DLthon_finetune_koBart/runs/9x0ocr7n' target=\"_blank\">fine-sweep-1</a></strong> to <a href='https://wandb.ai/aiffel_minions/DLthon_finetune_koBart' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/aiffel_minions/DLthon_finetune_koBart/sweeps/n6a4o84l' target=\"_blank\">https://wandb.ai/aiffel_minions/DLthon_finetune_koBart/sweeps/n6a4o84l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aiffel_minions/DLthon_finetune_koBart' target=\"_blank\">https://wandb.ai/aiffel_minions/DLthon_finetune_koBart</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/aiffel_minions/DLthon_finetune_koBart/sweeps/n6a4o84l' target=\"_blank\">https://wandb.ai/aiffel_minions/DLthon_finetune_koBart/sweeps/n6a4o84l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aiffel_minions/DLthon_finetune_koBart/runs/9x0ocr7n' target=\"_blank\">https://wandb.ai/aiffel_minions/DLthon_finetune_koBart/runs/9x0ocr7n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ffc87f8b4a4ee0965f4b3e60664e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 60/165 [05:24<09:29,  5.43s/it]"
     ]
    }
   ],
   "source": [
    "# 스윕 생성 및 에이전트 실행하기\n",
    "sweep_id = wandb.sweep(sweep_config, \n",
    "                       entity='aiffel_minions', \n",
    "                       project='DLthon_finetune_KoBART')\n",
    "wandb.agent(sweep_id, \n",
    "            function=sweep_train, \n",
    "            count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b168a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split, default_collate\n",
    "generator2 = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset, test_dataset  = random_split(dataset, [0.8, 0.1, 0.1], generator=generator2)\n",
    "\n",
    "train(train_dataset, val_dataset, test_dataset, default_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c504ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
